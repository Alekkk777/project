# Calcolo della cardinalità per le variabili categoriche
cardinality = data.select_dtypes(include=['object']).nunique()
print("Cardinalità delle variabili categoriche:\n", cardinality)
# Calcolo della varianza per le variabili numeriche
variance = data.select_dtypes(include=['float64', 'int64']).var()
low_variance = variance[variance < 0.01]  # Soglia di varianza bassa scelta arbitrariamente
print("Variabili con bassa varianza:\n", low_variance)
# Calcolo della matrice di correlazione
correlation_matrix = data.select_dtypes(include=['float64', 'int64']).corr()

# Identificazione di coppie di variabili con alta correlazione (es. soglia > 0.8 o < -0.8)
high_correlation = correlation_matrix.where(~np.tril(np.ones(correlation_matrix.shape)).astype(np.bool_))
high_correlation = high_correlation.stack().reset_index()
high_correlation = high_correlation[high_correlation[0].abs() > 0.8]  # Soglia di correlazione elevata
print("Coppie di variabili fortemente correlate:\n", high_correlation)




# Rimuovere le variabili 'sfid' e 'dt_rif'
data = data.drop(['sfid', 'dt_rif'], axis=1)

# Rimuovere una delle variabili fortemente correlate, ad esempio 'slope_ebit'
data = data.drop(['slope_ebit'], axis=1)
data.head(), data.info(), data.describe(include='all')



# Variabili numeriche di interesse
num_vars = ['revenues', 'pfn_ebitda', 'pn', 'ebitda']

# Istoogrammi
for var in num_vars:
    plt.figure(figsize=(10, 4))
    sns.histplot(data[var], kde=True, bins=30)
    plt.title(f'Distribuzione di {var}')
    plt.show()

# Boxplot
for var in num_vars:
    plt.figure(figsize=(10, 4))
    sns.boxplot(x=data[var])
    plt.title(f'Boxplot di {var}')
    plt.show()




import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder, RobustScaler
from sklearn.impute import SimpleImputer
from scipy.stats import boxcox
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC


# Definisci le colonne categoriche e numeriche
categorical_columns = ['juridical_form', 'dossier_type', 'application_source', 'credimi_industry', 'region', 'zone', 'gender']
numerical_columns = ['revenues', 'pfn_ebitda', 'pn', 'ebitda']

# Rimuovi righe con valori NaN nelle colonne categoriche
data.dropna(subset=categorical_columns, inplace=True)

# One-Hot Encoding delle variabili categoriche
encoder = OneHotEncoder(drop='first')
encoded_data = encoder.fit_transform(data[categorical_columns])
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out())

# Concatena le colonne codificate con il DataFrame originale
data.reset_index(drop=True, inplace=True)
data = pd.concat([data, encoded_df], axis=1)
data.drop(categorical_columns, axis=1, inplace=True)

# Imputazione dei valori mancanti con la mediana per le colonne numeriche
median_imputer = SimpleImputer(strategy='median')
data[numerical_columns] = median_imputer.fit_transform(data[numerical_columns])

# Assicurati che tutti i valori siano positivi prima delle trasformazioni Box-Cox
data[numerical_columns] += 1e-3

# Applica la trasformazione Box-Cox
for col in numerical_columns:
    data[col], _ = boxcox(data[col])

# Scala i dati con RobustScaler
scaler = RobustScaler()
data[numerical_columns] = scaler.fit_transform(data[numerical_columns])

# Preparazione dei dati per il training
X = data.drop('target', axis=1)
y = data['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Addestramento del modello SVC lineare
svc = SVC(kernel='linear')
svc.fit(X_train, y_train)

# Valutazione del modello
from sklearn.metrics import classification_report, accuracy_score
y_pred = svc.predict(X_test)
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))




# Seleziona solo le colonne numeriche per il calcolo della correlazione
numeric_data = data.select_dtypes(include=[np.number])

# Calcola la matrice di correlazione sulle colonne numeriche
correlation_matrix = numeric_data.corr()

# Estrazione della correlazione con il target e ordinamento dei valori
target_correlation = correlation_matrix['target'].sort_values(ascending=False)

# Stampa la correlazione delle variabili numeriche con il target
print("Correlazione delle variabili con il target:\n", target_correlation)

# Visualizzazione della correlazione con il target tramite un heatmap
plt.figure(figsize=(10, 12))
sns.heatmap(correlation_matrix[['target']].sort_values(by='target', ascending=False), annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlazione con il Target')
plt.show()


